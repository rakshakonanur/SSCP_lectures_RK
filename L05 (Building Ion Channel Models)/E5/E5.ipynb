{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E5.2 - Building ion current models from data \n",
    "\n",
    "In this exercise we will explore some of the challenges that come with optimizing a model to data. We'll use a moderately complex model for the ultra-rapidly activating delayed rectifier current ($I_{\\rm{Kur}}$). This model is simple in the sense that it has identical rate constants for each activating and deactivating transition, and it is linear. However, you'll see that there are still 12 parameters that can be varied during the fitting process, which can make for challenges in hand tuning the model to a simple activation curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a 5-state Markov model published by Zhou et al. 2012:\n",
    "\n",
    "<img src=\"fig/Model.svg\" width=400>\n",
    "\n",
    "Where: $$\\alpha{} = e^{\\frac{V-P1}{P2}}$$\n",
    "$$\\beta{} = \\frac{e^{\\frac{V-P3}{P4}}\\cdot{}e^{\\frac{-(V-P5)}{P6}}}{P7+P8\\cdot{}e^{\\frac{-(V-P9)}{P10}}}$$\n",
    "$$ K_1 = const_1 $$\n",
    "$$ K_2 = const_2 $$\n",
    "\n",
    "Below we will take some time to try to fit this model just to some activation data for this current. In this case we have also allowed the peak conductance ($g_K$) to be a free parameter for your tuning. See how close you can get to the experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import scipy.optimize as opt\n",
    "import math\n",
    "from ObFunc import f, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, FloatSlider\n",
    "import K_widget as K\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492aea7320df48739970d7ae6c617297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=45.0, continuous_update=False, description='P1', step=1.0), FloatSlideâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<K_widget.Markov_Widget at 0x78785d8a6030>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(K)\n",
    "K.Markov_Widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can probably see that this model is underdetermined and that there are far more parameters than necessary or helpful for fitting this activation curve. What do you think is the reason for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinatorial optimisation\n",
    "Next we will employ a commonly-used algorithm (the Nelder-Mead simplex, or AMOEBA) to optimise the parameter set, and see if it can beat you for accuracy. This algorithm is a form of derivative-free approach to optimise our voltage clamp activation function: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's be specific about the experimental data you will use for fitting. This is a conventional steady-state activation curve for the ultra-rapidly activating delayed rectifier current ($I_{Kur}$), which is largely carried by Kv1.5. The curve is as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSA_data = np.loadtxt(\"SS.txt\",dtype='float')\n",
    "\n",
    "V = SSA_data[:,0] # voltage\n",
    "I = SSA_data[:,1] # current\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(V,I,'b-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to define a cost function for comparing the model generated data and the experimental data we have imported. See if you can create this function from the inputs and outputs. First you will need to know the inputs and outputs for the function that simulates channel activation (Activation), for which the summary is shown below. Given a parameter vector (P), Voltage vector (V), and step duration scalar (duration), it returns the simulated time vector (t), open probability vector (Po), and peak $I_{Kur}$ vector (I_peak) as a dictionary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "```\n",
    "def Activation(P,V,duration):\n",
    "\n",
    "    'runs activation voltage protocol on the model'\n",
    "    'P is the vector of parameters [P1... P13]'\n",
    "    'V is the voltage at each step of the protocol [V1... V15]'\n",
    "    'duration is a variable specifying the length of each voltage clamp step in time - 1000 ms is conventional'\n",
    "    \n",
    "    return out = {'t':t,'Po':Po,'I_peak':model_peaks}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(P,V,I,duration):\n",
    "    \n",
    "    P = P.tolist() # Opt.fmin returns an array every iteration...\n",
    "                # but we pass a list to Activation, so we need to typeset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the optimization and see how it performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_length = 1000\n",
    "init_params = [45,20,65,50,20,15,1,0.02,29,15,1e-5,1e-5,0.5] # a starting guess for the parameters\n",
    "\n",
    "[P_opt, f_opt, iters, funcalls, warnflag] = opt.fmin(cost, init_params, args=(V,I,step_length), maxiter = 300, maxfun = 300, full_output=True, disp=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Finally plot your optimized data compared to the experimental data below. Did the algorithm do better than your hand tuning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
